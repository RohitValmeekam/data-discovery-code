{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if ConsolidateData(input_folder=./input_data, output_folder=./processed_data) is complete\n",
      "DEBUG: Checking if ReadFile(input_file=./input_data/Unemployment_Insurance_Program_Monthly_Claims_Data_for_California.csv) is complete\n",
      "INFO: Informed scheduler that task   ConsolidateData___input_data___processed_data_bae0eb4364   has status   PENDING\n",
      "INFO: Informed scheduler that task   ReadFile___input_data_Une_3cd13d818e   has status   PENDING\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 2\n",
      "INFO: [pid 97078] Worker Worker(salt=7535332105, workers=1, host=Rohits-MacBook-Pro.local, username=rohitvalmeekam, pid=97078) running   ReadFile(input_file=./input_data/Unemployment_Insurance_Program_Monthly_Claims_Data_for_California.csv)\n",
      "INFO: [pid 97078] Worker Worker(salt=7535332105, workers=1, host=Rohits-MacBook-Pro.local, username=rohitvalmeekam, pid=97078) done      ReadFile(input_file=./input_data/Unemployment_Insurance_Program_Monthly_Claims_Data_for_California.csv)\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   ReadFile___input_data_Une_3cd13d818e   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 1\n",
      "INFO: [pid 97078] Worker Worker(salt=7535332105, workers=1, host=Rohits-MacBook-Pro.local, username=rohitvalmeekam, pid=97078) running   ConsolidateData(input_folder=./input_data, output_folder=./processed_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./input_data/Unemployment_Insurance_Program_Monthly_Claims_Data_for_California', '.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [pid 97078] Worker Worker(salt=7535332105, workers=1, host=Rohits-MacBook-Pro.local, username=rohitvalmeekam, pid=97078) done      ConsolidateData(input_folder=./input_data, output_folder=./processed_data)\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   ConsolidateData___input_data___processed_data_bae0eb4364   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "INFO: Worker Worker(salt=7535332105, workers=1, host=Rohits-MacBook-Pro.local, username=rohitvalmeekam, pid=97078) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 2 tasks of which:\n",
      "* 2 ran successfully:\n",
      "    - 1 ConsolidateData(input_folder=./input_data, output_folder=./processed_data)\n",
      "    - 1 ReadFile(input_file=./input_data/Unemployment_Insurance_Program_Monthly_Claims_Data_for_California.csv)\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed CSV file: ./input_data/Unemployment_Insurance_Program_Monthly_Claims_Data_for_California.csv\n"
     ]
    }
   ],
   "source": [
    "import luigi\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "class ReadFile(luigi.Task):\n",
    "    input_file = luigi.Parameter()\n",
    "\n",
    "    def output(self):\n",
    "        # Generate a standardized output file path with a .csv extension\n",
    "        output_file = os.path.splitext(os.path.basename(self.input_file))[0]\n",
    "        return luigi.LocalTarget(output_file)\n",
    "\n",
    "    def run(self):\n",
    "        file_extension = os.path.splitext(self.input_file)[1].lower()\n",
    "        \n",
    "        if file_extension == '.csv':\n",
    "            # If the input format is CSV, just copy the file\n",
    "            shutil.copyfile(self.input_file, self.output().path)\n",
    "        elif file_extension == '.xlsx':\n",
    "            # Read Excel file and save as CSV\n",
    "            df = pd.read_excel(self.input_file)\n",
    "            df.to_csv(self.output().path, index=False)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
    "\n",
    "\n",
    "class ConsolidateData(luigi.Task):\n",
    "    input_folder = luigi.Parameter()\n",
    "    output_folder = luigi.Parameter(default=\"./processed_data\")\n",
    "\n",
    "    def requires(self):\n",
    "        input_files = [os.path.join(self.input_folder, filename) for filename in os.listdir(self.input_folder)]\n",
    "        return [ReadFile(input_file=input_file) for input_file in input_files]\n",
    "\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(self.output_folder)\n",
    "\n",
    "    def complete(self):\n",
    "        remaining_files = [filename for filename in os.listdir(self.input_folder)]\n",
    "        return len(remaining_files) == 0\n",
    "\n",
    "    def run(self):\n",
    "        for input_task in self.requires():\n",
    "            input_file = input_task.input_file  # Store the input file path\n",
    "            output_format = os.path.splitext(input_file)[1].lower()\n",
    "            print(os.path.splitext(input_file))\n",
    "            if output_format == '.csv':\n",
    "                # If the output format is CSV, you can continue with your existing CSV processing logic\n",
    "                input_df = pd.read_csv(input_file)\n",
    "                category = input(\"Enter the category for dataset '{}': \".format(os.path.basename(input_file)))\n",
    "                category_folder = os.path.join(self.output_folder, category)\n",
    "                os.makedirs(category_folder, exist_ok=True)\n",
    "                output_csv_path = os.path.join(category_folder, os.path.basename(input_file))\n",
    "                input_df.to_csv(output_csv_path, index=False)\n",
    "                print(f\"Processed CSV file: {input_file}\")\n",
    "            elif output_format == '.xlsx':\n",
    "                # Read Excel file and save as CSV\n",
    "                input_df = pd.read_excel(input_file)  # Corrected this line\n",
    "                category = input(\"Enter the category for dataset '{}': \".format(os.path.basename(input_file)))\n",
    "                category_folder = os.path.join(self.output_folder, category)\n",
    "                os.makedirs(category_folder, exist_ok=True)\n",
    "                output_csv_path = os.path.join(category_folder, os.path.basename(input_file))\n",
    "                input_df.to_csv(output_csv_path, index=False)\n",
    "                print(f\"Processed XLSX file: {input_file}\")\n",
    "            \n",
    "            # Delete the input file after processing\n",
    "            os.remove(input_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder_path = \"./input_data\" \n",
    "    output_folder_path = \"./processed_data\" \n",
    "    luigi.build([ConsolidateData(input_folder=input_folder_path, output_folder=output_folder_path)], local_scheduler=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
